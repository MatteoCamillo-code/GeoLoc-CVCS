{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0339322c",
   "metadata": {},
   "source": [
    "## PATH SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636aa887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST be first cell: set multiprocessing method for Windows\n",
    "import torch.multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "except RuntimeError:\n",
    "    pass  # Already set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d50292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# FOR LOCAL USE THIS LINES\n",
    "current = Path.cwd()\n",
    "src_path = current / \"src\" if (current / \"src\").exists() else current.parent\n",
    "\n",
    "# FOR COLAB USE THIS LINE INSTEAD\n",
    "# After -b insert the branch name if needed\n",
    "# !git clone -b refactoring https://github.com/MatteoCamillo-code/GeoLoc-CVCS.git\n",
    "# src_path = Path(\"/content/GeoLoc-CVCS/src\").resolve()\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "from utils.paths import find_project_root\n",
    "\n",
    "# Set working directory and sys.path properly\n",
    "project_root = find_project_root(src_path)\n",
    "data_dir = project_root / \"data\"\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "print(\"CWD:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f450636",
   "metadata": {},
   "source": [
    "## IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c976cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from configs.baseline_multi_head import TrainConfig\n",
    "\n",
    "from utils.seed import seed_everything\n",
    "from training.runner import fit\n",
    "\n",
    "from models.multi_head_classifier import MultiHeadClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ad6ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "cfg = TrainConfig()\n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "device = cfg.device if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad64c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camil\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
      "Path to dataset files: C:\\Users\\camil\\.cache\\kagglehub\\datasets\\josht000\\osv-mini-129k\\versions\\1/osv5m\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"josht000/osv-mini-129k\")\n",
    "path = path + \"/osv5m\"\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "image_root = path + \"/train_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f05014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\train_val_split_geocells.csv\n",
      "Cell centers CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\cell_center_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "train_val_path = data_dir / \"metadata/s2-geo-cells/train_val_split_geocells.csv\"\n",
    "cell_centers_path = data_dir / \"metadata/s2-geo-cells/cell_center_dataset.csv\"\n",
    "\n",
    "train_val_meta = pd.read_csv(train_val_path)\n",
    "cell_centers_df = pd.read_csv(cell_centers_path)\n",
    "\n",
    "print(\"Train/val CSV:\", train_val_path)\n",
    "print(\"Cell centers CSV:\", cell_centers_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662ad7d",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4888680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 100863\n",
      "Val size: 17803\n"
     ]
    }
   ],
   "source": [
    "from dataset.dataloader_utils import create_dataloaders\n",
    "\n",
    "IMG_SIZE = 224\n",
    "TRAIN_SUBSET_PCT = 100.0  # Use 100% of training data (or set to e.g., 10.0 for 10%)\n",
    "VAL_SUBSET_PCT = 100.0    # Use 100% of validation data\n",
    "\n",
    "# Create all dataloaders with a single function call\n",
    "loader_dict = create_dataloaders(\n",
    "    image_root=image_root,\n",
    "    csv_path=train_val_path,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.num_workers,\n",
    "    img_size=IMG_SIZE,\n",
    "    seed=cfg.seed,\n",
    "    train_subset_pct=TRAIN_SUBSET_PCT,\n",
    "    val_subset_pct=VAL_SUBSET_PCT,\n",
    "    augment=True,\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True if cfg.num_workers > 0 else False,\n",
    "    coarse_label_idx=cfg.coarse_label_idx,\n",
    ")\n",
    "\n",
    "train_loader = loader_dict[\"train_loader\"]\n",
    "val_loader = loader_dict[\"val_loader\"]\n",
    "label_maps = loader_dict[\"label_maps\"]\n",
    "\n",
    "print(f\"Train size: {loader_dict['train_size']}\")\n",
    "print(f\"Val size: {loader_dict['val_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10203f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output classes: [4741, 2508, 1336]\n"
     ]
    }
   ],
   "source": [
    "weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "resnet = resnet50(weights=weights)\n",
    "\n",
    "# number of classes depends on partition\n",
    "num_classes = list(map(\n",
    "    lambda idx: len(label_maps[f\"label_config_{idx + 1}\"]),\n",
    "    cfg.coarse_label_idx\n",
    "))\n",
    "\n",
    "backbone = nn.Sequential(\n",
    "    *list(resnet.children())[:-1],\n",
    "    nn.Flatten(1)\n",
    ")\n",
    "\n",
    "FEAT_DIM = 2048  # resnet50 feature dimension\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "# Optional: comment out if it causes issues on Windows/your PyTorch version\n",
    "# model = torch.compile(model, backend=\"aot_eager\")\n",
    "\n",
    "model = MultiHeadClassifier(\n",
    "    backbone=backbone,\n",
    "    feat_dim=FEAT_DIM,\n",
    "    head_dims=num_classes,\n",
    "    dropout=cfg.dropout,\n",
    "    coarse_level_idx=cfg.coarse_label_idx,\n",
    ").to(device)\n",
    "\n",
    "print(\"Output classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef1e57",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "342d07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "# WITH SGD OPTIMIZER the convergence is very slow\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=cfg.lr,\n",
    "#     momentum=cfg.momentum,\n",
    "#     weight_decay=cfg.weight_decay,\n",
    "#     nesterov=True\n",
    "# )\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=cfg.scheduler_step_size, gamma=cfg.scheduler_gamma)\n",
    "scaler = torch.amp.GradScaler(device=cfg.device, enabled=cfg.amp)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe789ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:54:11] INFO - Starting training...\n",
      "c:\\Users\\camil\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "[15:58:57] INFO - Epoch 1/30 | train loss=inf acc=11.97% | val loss=5.5420 acc=20.87% | time=285.88s\n",
      "[16:01:59] INFO - Epoch 2/30 | train loss=4.7928 acc=32.45% | val loss=4.9843 acc=26.41% | time=181.68s\n",
      "[16:05:10] INFO - Epoch 3/30 | train loss=4.0711 acc=39.05% | val loss=4.3701 acc=31.29% | time=191.10s\n",
      "[16:08:54] INFO - Epoch 4/30 | train loss=3.3230 acc=48.57% | val loss=4.0006 acc=34.53% | time=223.48s\n",
      "[16:11:57] INFO - Epoch 5/30 | train loss=2.8081 acc=55.84% | val loss=3.7340 acc=37.31% | time=182.09s\n",
      "[16:15:12] INFO - Epoch 6/30 | train loss=2.4283 acc=61.59% | val loss=3.5575 acc=38.93% | time=194.66s\n",
      "[16:18:09] INFO - Epoch 7/30 | train loss=2.1244 acc=66.24% | val loss=3.4198 acc=40.53% | time=177.09s\n",
      "[16:21:49] INFO - Epoch 8/30 | train loss=1.8835 acc=70.05% | val loss=3.3158 acc=41.51% | time=219.60s\n",
      "[16:24:54] INFO - Epoch 9/30 | train loss=1.6867 acc=73.25% | val loss=3.2291 acc=42.47% | time=184.35s\n",
      "[16:28:22] INFO - Epoch 10/30 | train loss=1.5150 acc=76.13% | val loss=3.1551 acc=43.20% | time=208.47s\n",
      "[16:31:17] INFO - Epoch 11/30 | train loss=1.3730 acc=78.39% | val loss=3.1141 acc=43.71% | time=174.26s\n",
      "[16:34:12] INFO - Epoch 12/30 | train loss=1.2461 acc=80.51% | val loss=3.0657 acc=44.09% | time=174.33s\n",
      "[16:37:07] INFO - Epoch 13/30 | train loss=1.1421 acc=82.17% | val loss=3.0342 acc=44.38% | time=174.84s\n",
      "[16:40:02] INFO - Epoch 14/30 | train loss=1.0479 acc=83.68% | val loss=3.0070 acc=44.93% | time=174.36s\n",
      "[16:42:56] INFO - Epoch 15/30 | train loss=0.9669 acc=84.95% | val loss=2.9901 acc=45.19% | time=174.07s\n",
      "[16:45:51] INFO - Epoch 16/30 | train loss=0.8928 acc=86.15% | val loss=2.9642 acc=45.41% | time=174.93s\n",
      "train:  10%|â–ˆ         | 80/788 [00:18<02:11,  5.37it/s, acc=90.60%, loss=0.8116]"
     ]
    }
   ],
   "source": [
    "history = fit(\n",
    "    cfg=cfg,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scaler=scaler,\n",
    "    use_tqdm=cfg.use_tqdm,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
