{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0339322c",
   "metadata": {},
   "source": [
    "## PATH SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636aa887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST be first cell: set multiprocessing method for Windows\n",
    "import torch.multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "except RuntimeError:\n",
    "    pass  # Already set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d50292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# FOR LOCAL USE THIS LINES\n",
    "current = Path.cwd()\n",
    "src_path = current / \"src\" if (current / \"src\").exists() else current.parent\n",
    "\n",
    "# FOR COLAB USE THIS LINE INSTEAD\n",
    "# BRANCH_NAME = \"main\"  # Change this to switch branches\n",
    "# !git clone -b {BRANCH_NAME} https://github.com/MatteoCamillo-code/GeoLoc-CVCS.git\n",
    "# !cd /content/GeoLoc-CVCS && git pull origin {BRANCH_NAME} && cd ..\n",
    "# src_path = Path(\"/content/GeoLoc-CVCS/src\").resolve()\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "from utils.paths import find_project_root\n",
    "\n",
    "# Set working directory and sys.path properly\n",
    "project_root = find_project_root(src_path)\n",
    "data_dir = project_root / \"data\"\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "print(\"CWD:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f450636",
   "metadata": {},
   "source": [
    "## IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c976cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from configs.baseline_multi_head_ISN import TrainConfig\n",
    "\n",
    "from utils.seed import seed_everything\n",
    "from utils.io import save_json\n",
    "from training.runner import fit\n",
    "\n",
    "from src.utils.logging import get_logger\n",
    "from src.utils.paths import abs_path\n",
    "\n",
    "from models.multi_head_classifier import MultiHeadClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ad6ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "cfg = TrainConfig()\n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "device = cfg.device if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad64c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camil\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
      "Path to dataset files: C:\\Users\\camil\\.cache\\kagglehub\\datasets\\josht000\\osv-mini-129k\\versions\\1/osv5m\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"josht000/osv-mini-129k\")\n",
    "path = path + \"/osv5m\"\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "image_root = path + \"/train_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f05014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\train_val_split_geocells.csv\n",
      "Cell centers CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\cell_center_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "train_val_path = data_dir / \"metadata/s2-geo-cells/train_val_split_geocells.csv\"\n",
    "cell_centers_path = data_dir / \"metadata/s2-geo-cells/cell_center_dataset.csv\"\n",
    "\n",
    "train_val_meta = pd.read_csv(train_val_path)\n",
    "cell_centers_df = pd.read_csv(cell_centers_path)\n",
    "\n",
    "print(\"Train/val CSV:\", train_val_path)\n",
    "print(\"Cell centers CSV:\", cell_centers_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662ad7d",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4888680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataloader_utils import create_dataloaders\n",
    "\n",
    "IMG_SIZE = 224\n",
    "TRAIN_SUBSET_PCT = 100.0  # Use 100% of training data (or set to e.g., 10.0 for 10%)\n",
    "VAL_SUBSET_PCT = 100.0    # Use 100% of validation data\n",
    "\n",
    "# Create all dataloaders with a single function call\n",
    "loader_dict = create_dataloaders(\n",
    "    image_root=image_root,\n",
    "    csv_path=train_val_path,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.num_workers,\n",
    "    img_size=IMG_SIZE,\n",
    "    seed=cfg.seed,\n",
    "    train_subset_pct=TRAIN_SUBSET_PCT,\n",
    "    val_subset_pct=VAL_SUBSET_PCT,\n",
    "    scenes=cfg.scenes,\n",
    "    augment=True,\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True if cfg.num_workers > 0 else False,\n",
    "    coarse_label_idx=cfg.coarse_label_idx,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef1e57",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10203f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output classes urban: [3101, 1850, 1091]\n",
      "Output classes natural: [4561, 2472, 1328]\n"
     ]
    }
   ],
   "source": [
    "weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "models = {}\n",
    "\n",
    "for sc in cfg.scenes:\n",
    "    resnet = resnet50(weights=weights)\n",
    "\n",
    "    # number of classes depends on partition\n",
    "    num_classes = list(map(\n",
    "        lambda idx: len(loader_dict[sc][\"label_maps\"][f\"label_config_{idx + 1}\"]),\n",
    "        cfg.coarse_label_idx\n",
    "    ))\n",
    "\n",
    "    backbone = nn.Sequential(\n",
    "        *list(resnet.children())[:-1],\n",
    "        nn.Flatten(1)\n",
    "    )\n",
    "\n",
    "    FEAT_DIM = 2048  # resnet50 feature dimension\n",
    "\n",
    "    resnet = resnet.to(device)\n",
    "    # Optional: comment out if it causes issues on Windows/your PyTorch version\n",
    "    # model = torch.compile(model, backend=\"aot_eager\")\n",
    "\n",
    "    model = MultiHeadClassifier(\n",
    "        backbone=backbone,\n",
    "        feat_dim=FEAT_DIM,\n",
    "        head_dims=num_classes,\n",
    "        dropout=cfg.dropout,\n",
    "        coarse_level_idx=cfg.coarse_label_idx,\n",
    "    ).to(device)\n",
    "    \n",
    "    models[sc] = model\n",
    "\n",
    "    print(f\"Output classes {sc}:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "342d07d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized training components for 2 scenes: ['urban', 'natural']\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "# Create optimizer, scheduler, and scaler for each model\n",
    "optimizers = {}\n",
    "schedulers = {}\n",
    "scalers = {}\n",
    "\n",
    "for scene, model in models.items():\n",
    "    optimizers[scene] = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    schedulers[scene] = StepLR(optimizers[scene], step_size=cfg.scheduler_step_size, gamma=cfg.scheduler_gamma)\n",
    "    scalers[scene] = torch.amp.GradScaler(device=cfg.device, enabled=cfg.amp)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(f\"Initialized training components for {len(models)} scenes: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba589c1",
   "metadata": {},
   "source": [
    "## TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe789ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:32:52] INFO - Starting training baseline_multi_head_ISN for scene urban ...\n",
      "[22:34:29] INFO - Epoch 1/25 | train loss=6.7759 acc=2.87% | val loss=6.2849 acc=5.89% | time=96.87s\n",
      "[22:35:24] INFO - Epoch 2/25 | train loss=5.7024 acc=12.27% | val loss=5.8295 acc=9.41% | time=54.19s\n",
      "[22:36:18] INFO - Epoch 3/25 | train loss=5.0323 acc=20.42% | val loss=5.5118 acc=12.12% | time=54.37s\n",
      "[22:37:12] INFO - Epoch 4/25 | train loss=4.4944 acc=28.80% | val loss=5.2835 acc=13.59% | time=54.04s\n",
      "[22:38:07] INFO - Epoch 5/25 | train loss=4.0440 acc=36.35% | val loss=5.0888 acc=15.06% | time=54.17s\n",
      "[22:39:01] INFO - Epoch 6/25 | train loss=3.6780 acc=44.72% | val loss=5.0096 acc=16.49% | time=53.56s\n",
      "[22:39:55] INFO - Epoch 7/25 | train loss=3.5000 acc=48.15% | val loss=4.9513 acc=16.70% | time=53.61s\n",
      "[22:40:48] INFO - Epoch 8/25 | train loss=3.3411 acc=50.96% | val loss=4.8837 acc=17.35% | time=53.59s\n",
      "[22:41:42] INFO - Epoch 9/25 | train loss=3.1936 acc=53.56% | val loss=4.8243 acc=18.11% | time=53.67s\n",
      "[22:42:36] INFO - Epoch 10/25 | train loss=3.0515 acc=56.11% | val loss=4.7764 acc=18.44% | time=53.54s\n",
      "[22:43:30] INFO - Epoch 11/25 | train loss=2.9218 acc=58.81% | val loss=4.7856 acc=18.48% | time=53.39s\n",
      "[22:44:24] INFO - Epoch 12/25 | train loss=2.8485 acc=59.93% | val loss=4.7344 acc=19.05% | time=53.72s\n",
      "[22:45:17] INFO - Epoch 13/25 | train loss=2.7936 acc=60.81% | val loss=4.7185 acc=19.12% | time=53.54s\n",
      "[22:46:11] INFO - Epoch 14/25 | train loss=2.7479 acc=61.55% | val loss=4.6996 acc=19.40% | time=53.53s\n",
      "[22:47:05] INFO - Epoch 15/25 | train loss=2.6801 acc=62.46% | val loss=4.6833 acc=19.79% | time=53.49s\n",
      "[22:47:59] INFO - Epoch 16/25 | train loss=2.6291 acc=63.62% | val loss=4.6664 acc=19.79% | time=53.58s\n",
      "[22:48:52] INFO - Epoch 17/25 | train loss=2.5994 acc=64.02% | val loss=4.6646 acc=19.81% | time=53.51s\n",
      "[22:49:46] INFO - Epoch 18/25 | train loss=2.5730 acc=64.48% | val loss=4.6523 acc=19.96% | time=53.43s\n",
      "[22:50:40] INFO - Epoch 19/25 | train loss=2.5370 acc=65.31% | val loss=4.6490 acc=20.03% | time=53.67s\n",
      "[22:51:34] INFO - Epoch 20/25 | train loss=2.5196 acc=65.25% | val loss=4.6415 acc=20.14% | time=53.59s\n",
      "[22:52:27] INFO - Epoch 21/25 | train loss=2.4911 acc=66.02% | val loss=4.6443 acc=19.98% | time=53.51s\n",
      "[22:53:21] INFO - Epoch 22/25 | train loss=2.4701 acc=66.26% | val loss=4.6307 acc=20.41% | time=53.55s\n",
      "[22:54:15] INFO - Epoch 23/25 | train loss=2.4655 acc=66.25% | val loss=4.6332 acc=20.00% | time=53.38s\n",
      "[22:55:08] INFO - Epoch 24/25 | train loss=2.4546 acc=66.51% | val loss=4.6355 acc=19.88% | time=53.62s\n",
      "[22:56:02] INFO - Epoch 25/25 | train loss=2.4377 acc=66.68% | val loss=4.6339 acc=20.16% | time=53.58s\n",
      "[22:56:02] INFO - Training completed.\n",
      "[22:56:02] INFO - Starting training baseline_multi_head_ISN for scene natural ...\n",
      "[22:59:55] INFO - Epoch 1/25 | train loss=6.3311 acc=13.82% | val loss=5.3600 acc=23.08% | time=233.17s\n",
      "[23:02:03] INFO - Epoch 2/25 | train loss=4.4406 acc=35.40% | val loss=4.4162 acc=32.93% | time=128.01s\n",
      "[23:04:24] INFO - Epoch 3/25 | train loss=3.4778 acc=47.63% | val loss=3.8510 acc=38.83% | time=140.78s\n",
      "[23:07:27] INFO - Epoch 4/25 | train loss=2.8574 acc=55.91% | val loss=3.5263 acc=42.51% | time=182.45s\n",
      "[23:09:39] INFO - Epoch 5/25 | train loss=2.4077 acc=62.61% | val loss=3.2724 acc=45.04% | time=131.83s\n",
      "[23:11:46] INFO - Epoch 6/25 | train loss=2.0909 acc=68.30% | val loss=3.1472 acc=46.86% | time=126.70s\n",
      "[23:13:56] INFO - Epoch 7/25 | train loss=1.9415 acc=70.68% | val loss=3.0700 acc=47.72% | time=129.59s\n",
      "[23:16:04] INFO - Epoch 8/25 | train loss=1.8067 acc=72.86% | val loss=2.9767 acc=48.80% | time=127.80s\n",
      "[23:18:18] INFO - Epoch 9/25 | train loss=1.6949 acc=74.62% | val loss=2.9240 acc=49.42% | time=133.38s\n",
      "[23:20:23] INFO - Epoch 10/25 | train loss=1.5834 acc=76.21% | val loss=2.8527 acc=50.07% | time=124.70s\n",
      "[23:22:59] INFO - Epoch 11/25 | train loss=1.4833 acc=78.23% | val loss=2.8227 acc=50.46% | time=155.53s\n",
      "[23:25:08] INFO - Epoch 12/25 | train loss=1.4406 acc=78.87% | val loss=2.7935 acc=50.81% | time=129.26s\n",
      "[23:27:39] INFO - Epoch 13/25 | train loss=1.3940 acc=79.64% | val loss=2.7870 acc=51.05% | time=150.59s\n",
      "[23:29:48] INFO - Epoch 14/25 | train loss=1.3495 acc=80.29% | val loss=2.7505 acc=51.20% | time=128.91s\n",
      "[23:31:55] INFO - Epoch 15/25 | train loss=1.3063 acc=80.97% | val loss=2.7275 acc=51.55% | time=126.44s\n",
      "[23:34:04] INFO - Epoch 16/25 | train loss=1.2620 acc=81.79% | val loss=2.7148 acc=51.60% | time=128.76s\n",
      "[23:36:44] INFO - Epoch 17/25 | train loss=1.2456 acc=82.05% | val loss=2.7059 acc=51.76% | time=159.57s\n",
      "[23:38:48] INFO - Epoch 18/25 | train loss=1.2245 acc=82.36% | val loss=2.6896 acc=51.88% | time=123.89s\n",
      "[23:40:52] INFO - Epoch 19/25 | train loss=1.2155 acc=82.51% | val loss=2.6928 acc=52.00% | time=123.68s\n",
      "[23:42:56] INFO - Epoch 20/25 | train loss=1.1927 acc=82.85% | val loss=2.6708 acc=52.13% | time=123.60s\n",
      "[23:45:00] INFO - Epoch 21/25 | train loss=1.1720 acc=83.32% | val loss=2.6613 acc=52.14% | time=123.57s\n",
      "[23:47:04] INFO - Epoch 22/25 | train loss=1.1644 acc=83.39% | val loss=2.6672 acc=52.20% | time=123.69s\n",
      "[23:49:08] INFO - Epoch 23/25 | train loss=1.1577 acc=83.50% | val loss=2.6507 acc=52.35% | time=123.67s\n",
      "[23:51:12] INFO - Epoch 24/25 | train loss=1.1407 acc=83.87% | val loss=2.6542 acc=52.36% | time=123.61s\n",
      "[23:53:16] INFO - Epoch 25/25 | train loss=1.1377 acc=83.81% | val loss=2.6424 acc=52.43% | time=123.60s\n",
      "[23:53:16] INFO - Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Train each scene's model separately\n",
    "histories = {}\n",
    "logger = get_logger(log_file=str(abs_path(cfg.output_dir, \"logs\", \"train.log\")))\n",
    "\n",
    "for scene in models.keys():\n",
    "    history = fit(\n",
    "        cfg=cfg,\n",
    "        model=models[scene],\n",
    "        train_loader=loader_dict[scene][\"train_loader\"],\n",
    "        val_loader=loader_dict[scene][\"val_loader\"],\n",
    "        optimizer=optimizers[scene],\n",
    "        criterion=criterion,\n",
    "        scaler=scalers[scene],\n",
    "        use_tqdm=cfg.use_tqdm,\n",
    "        scheduler=schedulers[scene],\n",
    "        logger=logger,\n",
    "        scene=scene,\n",
    "    )\n",
    "    \n",
    "    histories[scene] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc626f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved history for urban: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\outputs\\history\\baseline_multi_head_ISN_urban_history.json\n",
      "Saved history for natural: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\outputs\\history\\baseline_multi_head_ISN_natural_history.json\n"
     ]
    }
   ],
   "source": [
    "# Save history for each scene\n",
    "for scene, history in histories.items():\n",
    "    history_path = project_root / \"outputs\" / \"history\" / f\"{cfg.model_name}_{scene}_history.json\"\n",
    "    save_json(obj=history, path=history_path)\n",
    "    print(f\"Saved history for {scene}: {history_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
