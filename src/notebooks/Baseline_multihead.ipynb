{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0339322c",
   "metadata": {},
   "source": [
    "## PATH SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636aa887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST be first cell: set multiprocessing method for Windows\n",
    "import torch.multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "except RuntimeError:\n",
    "    pass  # Already set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d50292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# FOR LOCAL USE THIS LINES\n",
    "current = Path.cwd()\n",
    "src_path = current / \"src\" if (current / \"src\").exists() else current.parent\n",
    "\n",
    "# FOR COLAB USE THIS LINE INSTEAD\n",
    "# BRANCH_NAME = \"main\"  # Change this to switch branches\n",
    "# !git clone -b {BRANCH_NAME} https://github.com/MatteoCamillo-code/GeoLoc-CVCS.git\n",
    "# !cd /content/GeoLoc-CVCS && git pull origin {BRANCH_NAME} && cd ..\n",
    "# src_path = Path(\"/content/GeoLoc-CVCS/src\").resolve()\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "from utils.paths import find_project_root\n",
    "\n",
    "# Set working directory and sys.path properly\n",
    "project_root = find_project_root(src_path)\n",
    "data_dir = project_root / \"data\"\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "print(\"CWD:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f450636",
   "metadata": {},
   "source": [
    "## IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c976cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from configs.baseline import TrainConfig\n",
    "\n",
    "from utils.seed import seed_everything\n",
    "from utils.io import save_json\n",
    "from training.runner import fit\n",
    "\n",
    "from models.multi_head_classifier import MultiHeadClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ad6ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "cfg = TrainConfig()\n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "device = cfg.device if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad64c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camil\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
      "Path to dataset files: C:\\Users\\camil\\.cache\\kagglehub\\datasets\\josht000\\osv-mini-129k\\versions\\1/osv5m\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"josht000/osv-mini-129k\")\n",
    "path = path + \"/osv5m\"\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "image_root = path + \"/train_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f05014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\train_val_split_geocells.csv\n",
      "Cell centers CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\cell_center_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "train_val_path = data_dir / \"metadata/s2-geo-cells/train_val_split_geocells.csv\"\n",
    "cell_centers_path = data_dir / \"metadata/s2-geo-cells/cell_center_dataset.csv\"\n",
    "\n",
    "train_val_meta = pd.read_csv(train_val_path)\n",
    "cell_centers_df = pd.read_csv(cell_centers_path)\n",
    "\n",
    "print(\"Train/val CSV:\", train_val_path)\n",
    "print(\"Cell centers CSV:\", cell_centers_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662ad7d",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4888680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 100863\n",
      "Val size: 0\n"
     ]
    }
   ],
   "source": [
    "from dataset.dataloader_utils import create_dataloaders\n",
    "\n",
    "IMG_SIZE = 224\n",
    "TRAIN_SUBSET_PCT = 100.0  # Use 100% of training data (or set to e.g., 10.0 for 10%)\n",
    "VAL_SUBSET_PCT = 100.0    # Use 100% of validation data\n",
    "\n",
    "# Create all dataloaders with a single function call\n",
    "loader_dict = create_dataloaders(\n",
    "    image_root=image_root,\n",
    "    csv_path=train_val_path,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.num_workers,\n",
    "    img_size=IMG_SIZE,\n",
    "    seed=cfg.seed,\n",
    "    train_subset_pct=TRAIN_SUBSET_PCT,\n",
    "    val_subset_pct=VAL_SUBSET_PCT,\n",
    "    augment=True,\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True if cfg.num_workers > 0 else False,\n",
    "    coarse_label_idx=cfg.coarse_label_idx,\n",
    ")\n",
    "\n",
    "train_loader = loader_dict[\"train_loader\"]\n",
    "val_loader = loader_dict[\"val_loader\"]\n",
    "label_maps = loader_dict[\"label_maps\"]\n",
    "\n",
    "print(f\"Train size: {loader_dict['train_size']}\")\n",
    "print(f\"Val size: {loader_dict['val_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10203f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output classes: [2508]\n"
     ]
    }
   ],
   "source": [
    "weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "resnet = resnet50(weights=weights)\n",
    "\n",
    "# number of classes depends on partition\n",
    "num_classes = list(map(\n",
    "    lambda idx: len(label_maps[f\"label_config_{idx + 1}\"]),\n",
    "    cfg.coarse_label_idx\n",
    "))\n",
    "\n",
    "backbone = nn.Sequential(\n",
    "    *list(resnet.children())[:-1],\n",
    "    nn.Flatten(1)\n",
    ")\n",
    "\n",
    "FEAT_DIM = 2048  # resnet50 feature dimension\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "# Optional: comment out if it causes issues on Windows/your PyTorch version\n",
    "# model = torch.compile(model, backend=\"aot_eager\")\n",
    "\n",
    "model = MultiHeadClassifier(\n",
    "    backbone=backbone,\n",
    "    feat_dim=FEAT_DIM,\n",
    "    head_dims=num_classes,\n",
    "    dropout=cfg.dropout,\n",
    "    coarse_level_idx=cfg.coarse_label_idx,\n",
    ").to(device)\n",
    "\n",
    "print(\"Output classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef1e57",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "342d07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "# WITH SGD OPTIMIZER the convergence is very slow\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=cfg.lr,\n",
    "#     momentum=cfg.momentum,\n",
    "#     weight_decay=cfg.weight_decay,\n",
    "#     nesterov=True\n",
    "# )\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=cfg.scheduler_step_size, gamma=cfg.scheduler_gamma)\n",
    "scaler = torch.amp.GradScaler(device=cfg.device, enabled=cfg.amp)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe789ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:56:56] INFO - Starting training baseline_single_head...\n",
      "c:\\Users\\camil\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "[19:00:17] INFO - Epoch 1/30 | train loss=6.2959 acc=12.49% | val loss=5.3358 acc=21.68% | time=200.43s\n",
      "[19:03:07] INFO - Epoch 2/30 | train loss=4.6881 acc=31.33% | val loss=4.7951 acc=26.96% | time=169.67s\n",
      "[19:05:56] INFO - Epoch 3/30 | train loss=4.0139 acc=37.80% | val loss=4.1989 acc=32.16% | time=169.57s\n",
      "[19:08:45] INFO - Epoch 4/30 | train loss=3.3259 acc=46.51% | val loss=3.8397 acc=35.51% | time=168.25s\n",
      "[19:11:33] INFO - Epoch 5/30 | train loss=2.8537 acc=53.35% | val loss=3.5830 acc=37.97% | time=168.13s\n",
      "[19:14:21] INFO - Epoch 6/30 | train loss=2.5029 acc=58.71% | val loss=3.4078 acc=39.95% | time=167.97s\n",
      "[19:17:10] INFO - Epoch 7/30 | train loss=2.2217 acc=63.01% | val loss=3.2702 acc=41.66% | time=168.25s\n",
      "[19:19:58] INFO - Epoch 8/30 | train loss=1.9946 acc=66.75% | val loss=3.1688 acc=42.56% | time=168.05s\n",
      "[19:22:46] INFO - Epoch 9/30 | train loss=1.8094 acc=69.76% | val loss=3.0815 acc=43.31% | time=168.17s\n",
      "[19:25:35] INFO - Epoch 10/30 | train loss=1.6435 acc=72.69% | val loss=3.0041 acc=44.54% | time=168.14s\n",
      "[19:28:23] INFO - Epoch 11/30 | train loss=1.5062 acc=75.00% | val loss=2.9574 acc=44.84% | time=168.28s\n",
      "[19:31:11] INFO - Epoch 12/30 | train loss=1.3811 acc=77.27% | val loss=2.9052 acc=45.09% | time=167.90s\n",
      "[19:34:00] INFO - Epoch 13/30 | train loss=1.2786 acc=79.01% | val loss=2.8719 acc=45.28% | time=168.31s\n",
      "[19:36:48] INFO - Epoch 14/30 | train loss=1.1836 acc=80.65% | val loss=2.8436 acc=46.05% | time=168.19s\n",
      "[19:39:36] INFO - Epoch 15/30 | train loss=1.0996 acc=82.03% | val loss=2.8250 acc=46.30% | time=168.14s\n",
      "[19:42:24] INFO - Epoch 16/30 | train loss=1.0232 acc=83.45% | val loss=2.7957 acc=46.45% | time=168.02s\n",
      "[19:45:13] INFO - Epoch 17/30 | train loss=0.9573 acc=84.61% | val loss=2.7953 acc=46.51% | time=168.31s\n",
      "[19:48:01] INFO - Epoch 18/30 | train loss=0.8952 acc=85.57% | val loss=2.7660 acc=46.83% | time=168.04s\n",
      "[19:50:50] INFO - Epoch 19/30 | train loss=0.8443 acc=86.41% | val loss=2.7536 acc=47.09% | time=168.30s\n",
      "[19:53:38] INFO - Epoch 20/30 | train loss=0.7889 acc=87.55% | val loss=2.7529 acc=46.91% | time=167.96s\n",
      "[19:56:26] INFO - Epoch 21/30 | train loss=0.7473 acc=88.10% | val loss=2.7499 acc=47.02% | time=168.17s\n",
      "[19:59:14] INFO - Epoch 22/30 | train loss=0.7155 acc=88.50% | val loss=2.7301 acc=47.65% | time=168.11s\n",
      "[20:02:03] INFO - Epoch 23/30 | train loss=0.6687 acc=89.32% | val loss=2.7407 acc=47.48% | time=168.42s\n",
      "[20:04:51] INFO - Epoch 24/30 | train loss=0.6358 acc=89.88% | val loss=2.7303 acc=47.54% | time=168.08s\n",
      "[20:07:39] INFO - Epoch 25/30 | train loss=0.6093 acc=90.30% | val loss=2.7296 acc=47.80% | time=168.17s\n",
      "[20:10:27] INFO - Epoch 26/30 | train loss=0.5772 acc=90.83% | val loss=2.7260 acc=47.91% | time=168.28s\n",
      "[20:13:20] INFO - Epoch 27/30 | train loss=0.5495 acc=91.28% | val loss=2.7262 acc=47.57% | time=172.71s\n",
      "[20:16:08] INFO - Epoch 28/30 | train loss=0.5283 acc=91.57% | val loss=2.7205 acc=48.01% | time=168.22s\n",
      "[20:18:57] INFO - Epoch 29/30 | train loss=0.5100 acc=91.84% | val loss=2.7339 acc=48.06% | time=168.23s\n",
      "[20:21:45] INFO - Epoch 30/30 | train loss=0.4835 acc=92.31% | val loss=2.7285 acc=48.07% | time=168.12s\n"
     ]
    }
   ],
   "source": [
    "history = fit(\n",
    "    cfg=cfg,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scaler=scaler,\n",
    "    use_tqdm=cfg.use_tqdm,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc626f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(\n",
    "    obj=history,\n",
    "    path=project_root / \"outputs\" / \"history\" / (cfg.model_name + \"_history.json\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
