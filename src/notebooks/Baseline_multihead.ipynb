{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0339322c",
   "metadata": {},
   "source": [
    "## PATH SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636aa887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST be first cell: set multiprocessing method for Windows\n",
    "import torch.multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "except RuntimeError:\n",
    "    pass  # Already set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d50292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# FOR LOCAL USE THIS LINES\n",
    "current = Path.cwd()\n",
    "src_path = current / \"src\" if (current / \"src\").exists() else current.parent\n",
    "\n",
    "# FOR COLAB USE THIS LINE INSTEAD\n",
    "# After -b insert the branch name if needed\n",
    "# !git clone -b refactoring https://github.com/MatteoCamillo-code/GeoLoc-CVCS.git\n",
    "# src_path = Path(\"/content/GeoLoc-CVCS/src\").resolve()\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "from utils.paths import find_project_root\n",
    "\n",
    "# Set working directory and sys.path properly\n",
    "project_root = find_project_root(src_path)\n",
    "data_dir = project_root / \"data\"\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "print(\"CWD:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f450636",
   "metadata": {},
   "source": [
    "## IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c976cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from configs.baseline_multi_head import TrainConfig\n",
    "\n",
    "from utils.seed import seed_everything\n",
    "from utils.io import save_json\n",
    "from training.runner import fit\n",
    "\n",
    "from models.multi_head_classifier import MultiHeadClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ad6ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "cfg = TrainConfig()\n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "device = cfg.device if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad64c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camil\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
      "Path to dataset files: C:\\Users\\camil\\.cache\\kagglehub\\datasets\\josht000\\osv-mini-129k\\versions\\1/osv5m\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"josht000/osv-mini-129k\")\n",
    "path = path + \"/osv5m\"\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "image_root = path + \"/train_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f05014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\train_val_split_geocells.csv\n",
      "Cell centers CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\cell_center_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "train_val_path = data_dir / \"metadata/s2-geo-cells/train_val_split_geocells.csv\"\n",
    "cell_centers_path = data_dir / \"metadata/s2-geo-cells/cell_center_dataset.csv\"\n",
    "\n",
    "train_val_meta = pd.read_csv(train_val_path)\n",
    "cell_centers_df = pd.read_csv(cell_centers_path)\n",
    "\n",
    "print(\"Train/val CSV:\", train_val_path)\n",
    "print(\"Cell centers CSV:\", cell_centers_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662ad7d",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4888680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 100863\n",
      "Val size: 17803\n"
     ]
    }
   ],
   "source": [
    "from dataset.dataloader_utils import create_dataloaders\n",
    "\n",
    "IMG_SIZE = 224\n",
    "TRAIN_SUBSET_PCT = 100.0  # Use 100% of training data (or set to e.g., 10.0 for 10%)\n",
    "VAL_SUBSET_PCT = 100.0    # Use 100% of validation data\n",
    "\n",
    "# Create all dataloaders with a single function call\n",
    "loader_dict = create_dataloaders(\n",
    "    image_root=image_root,\n",
    "    csv_path=train_val_path,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.num_workers,\n",
    "    img_size=IMG_SIZE,\n",
    "    seed=cfg.seed,\n",
    "    train_subset_pct=TRAIN_SUBSET_PCT,\n",
    "    val_subset_pct=VAL_SUBSET_PCT,\n",
    "    augment=True,\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True if cfg.num_workers > 0 else False,\n",
    "    coarse_label_idx=cfg.coarse_label_idx,\n",
    ")\n",
    "\n",
    "train_loader = loader_dict[\"train_loader\"]\n",
    "val_loader = loader_dict[\"val_loader\"]\n",
    "label_maps = loader_dict[\"label_maps\"]\n",
    "\n",
    "print(f\"Train size: {loader_dict['train_size']}\")\n",
    "print(f\"Val size: {loader_dict['val_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10203f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output classes: [4741, 2508, 1336]\n"
     ]
    }
   ],
   "source": [
    "weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "resnet = resnet50(weights=weights)\n",
    "\n",
    "# number of classes depends on partition\n",
    "num_classes = list(map(\n",
    "    lambda idx: len(label_maps[f\"label_config_{idx + 1}\"]),\n",
    "    cfg.coarse_label_idx\n",
    "))\n",
    "\n",
    "backbone = nn.Sequential(\n",
    "    *list(resnet.children())[:-1],\n",
    "    nn.Flatten(1)\n",
    ")\n",
    "\n",
    "FEAT_DIM = 2048  # resnet50 feature dimension\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "# Optional: comment out if it causes issues on Windows/your PyTorch version\n",
    "# model = torch.compile(model, backend=\"aot_eager\")\n",
    "\n",
    "model = MultiHeadClassifier(\n",
    "    backbone=backbone,\n",
    "    feat_dim=FEAT_DIM,\n",
    "    head_dims=num_classes,\n",
    "    dropout=cfg.dropout,\n",
    "    coarse_level_idx=cfg.coarse_label_idx,\n",
    ").to(device)\n",
    "\n",
    "print(\"Output classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef1e57",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "342d07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "# WITH SGD OPTIMIZER the convergence is very slow\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=cfg.lr,\n",
    "#     momentum=cfg.momentum,\n",
    "#     weight_decay=cfg.weight_decay,\n",
    "#     nesterov=True\n",
    "# )\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=cfg.scheduler_step_size, gamma=cfg.scheduler_gamma)\n",
    "scaler = torch.amp.GradScaler(device=cfg.device, enabled=cfg.amp)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe789ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:54:11] INFO - Starting training...\n",
      "c:\\Users\\camil\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "[15:58:57] INFO - Epoch 1/30 | train loss=inf acc=11.97% | val loss=5.5420 acc=20.87% | time=285.88s\n",
      "[16:01:59] INFO - Epoch 2/30 | train loss=4.7928 acc=32.45% | val loss=4.9843 acc=26.41% | time=181.68s\n",
      "[16:05:10] INFO - Epoch 3/30 | train loss=4.0711 acc=39.05% | val loss=4.3701 acc=31.29% | time=191.10s\n",
      "[16:08:54] INFO - Epoch 4/30 | train loss=3.3230 acc=48.57% | val loss=4.0006 acc=34.53% | time=223.48s\n",
      "[16:11:57] INFO - Epoch 5/30 | train loss=2.8081 acc=55.84% | val loss=3.7340 acc=37.31% | time=182.09s\n",
      "[16:15:12] INFO - Epoch 6/30 | train loss=2.4283 acc=61.59% | val loss=3.5575 acc=38.93% | time=194.66s\n",
      "[16:18:09] INFO - Epoch 7/30 | train loss=2.1244 acc=66.24% | val loss=3.4198 acc=40.53% | time=177.09s\n",
      "[16:21:49] INFO - Epoch 8/30 | train loss=1.8835 acc=70.05% | val loss=3.3158 acc=41.51% | time=219.60s\n",
      "[16:24:54] INFO - Epoch 9/30 | train loss=1.6867 acc=73.25% | val loss=3.2291 acc=42.47% | time=184.35s\n",
      "[16:28:22] INFO - Epoch 10/30 | train loss=1.5150 acc=76.13% | val loss=3.1551 acc=43.20% | time=208.47s\n",
      "[16:31:17] INFO - Epoch 11/30 | train loss=1.3730 acc=78.39% | val loss=3.1141 acc=43.71% | time=174.26s\n",
      "[16:34:12] INFO - Epoch 12/30 | train loss=1.2461 acc=80.51% | val loss=3.0657 acc=44.09% | time=174.33s\n",
      "[16:37:07] INFO - Epoch 13/30 | train loss=1.1421 acc=82.17% | val loss=3.0342 acc=44.38% | time=174.84s\n",
      "[16:40:02] INFO - Epoch 14/30 | train loss=1.0479 acc=83.68% | val loss=3.0070 acc=44.93% | time=174.36s\n",
      "[16:42:56] INFO - Epoch 15/30 | train loss=0.9669 acc=84.95% | val loss=2.9901 acc=45.19% | time=174.07s\n",
      "[16:45:51] INFO - Epoch 16/30 | train loss=0.8928 acc=86.15% | val loss=2.9642 acc=45.41% | time=174.93s\n",
      "[16:48:46] INFO - Epoch 17/30 | train loss=0.8301 acc=87.12% | val loss=2.9651 acc=45.62% | time=174.06s\n",
      "[16:51:41] INFO - Epoch 18/30 | train loss=0.7729 acc=88.02% | val loss=2.9423 acc=45.73% | time=175.13s\n",
      "[16:54:36] INFO - Epoch 19/30 | train loss=0.7243 acc=88.77% | val loss=2.9316 acc=46.01% | time=174.98s\n",
      "[16:57:30] INFO - Epoch 20/30 | train loss=0.6745 acc=89.66% | val loss=2.9337 acc=45.94% | time=173.15s\n",
      "[17:00:22] INFO - Epoch 21/30 | train loss=0.6358 acc=90.09% | val loss=2.9355 acc=46.04% | time=172.43s\n",
      "[17:03:15] INFO - Epoch 22/30 | train loss=0.6085 acc=90.43% | val loss=2.9115 acc=46.53% | time=172.17s\n",
      "[17:06:08] INFO - Epoch 23/30 | train loss=0.5664 acc=91.11% | val loss=2.9286 acc=46.38% | time=172.91s\n",
      "[17:09:03] INFO - Epoch 24/30 | train loss=0.5377 acc=91.55% | val loss=2.9219 acc=46.65% | time=174.68s\n",
      "[17:11:58] INFO - Epoch 25/30 | train loss=0.5140 acc=91.86% | val loss=2.9239 acc=46.60% | time=175.05s\n",
      "[17:14:53] INFO - Epoch 26/30 | train loss=0.4878 acc=92.29% | val loss=2.9170 acc=46.82% | time=175.17s\n",
      "[17:17:48] INFO - Epoch 27/30 | train loss=0.4631 acc=92.62% | val loss=2.9256 acc=46.64% | time=173.99s\n",
      "[17:20:41] INFO - Epoch 28/30 | train loss=0.4452 acc=92.90% | val loss=2.9168 acc=46.97% | time=173.50s\n",
      "[17:23:35] INFO - Epoch 29/30 | train loss=0.4300 acc=93.07% | val loss=2.9391 acc=47.00% | time=173.37s\n",
      "[17:26:29] INFO - Epoch 30/30 | train loss=0.4077 acc=93.40% | val loss=2.9333 acc=46.96% | time=173.79s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [inf,\n",
       "  4.792789936065674,\n",
       "  4.071115016937256,\n",
       "  3.32296085357666,\n",
       "  2.8081016540527344,\n",
       "  2.42832612991333,\n",
       "  2.1244301795959473,\n",
       "  1.8834999799728394,\n",
       "  1.686692714691162,\n",
       "  1.5149797201156616,\n",
       "  1.3729884624481201,\n",
       "  1.2461293935775757,\n",
       "  1.1420567035675049,\n",
       "  1.047863245010376,\n",
       "  0.9668921828269958,\n",
       "  0.8928302526473999,\n",
       "  0.8300926089286804,\n",
       "  0.7729223966598511,\n",
       "  0.7242932915687561,\n",
       "  0.674541711807251,\n",
       "  0.6357662081718445,\n",
       "  0.6085418462753296,\n",
       "  0.566426694393158,\n",
       "  0.537732720375061,\n",
       "  0.5140494704246521,\n",
       "  0.487815260887146,\n",
       "  0.4630505442619324,\n",
       "  0.4451505243778229,\n",
       "  0.4300491213798523,\n",
       "  0.4076598882675171],\n",
       " 'train_acc': [0.11965346336364746,\n",
       "  0.32446539402008057,\n",
       "  0.3904608488082886,\n",
       "  0.48566100001335144,\n",
       "  0.5584166646003723,\n",
       "  0.6158762574195862,\n",
       "  0.662397563457489,\n",
       "  0.7005265355110168,\n",
       "  0.7324962019920349,\n",
       "  0.7612883448600769,\n",
       "  0.7839301824569702,\n",
       "  0.8050729036331177,\n",
       "  0.8217409253120422,\n",
       "  0.8368092775344849,\n",
       "  0.8494839072227478,\n",
       "  0.861539900302887,\n",
       "  0.8712431192398071,\n",
       "  0.88023841381073,\n",
       "  0.8877126574516296,\n",
       "  0.8965712189674377,\n",
       "  0.9009193181991577,\n",
       "  0.9042762517929077,\n",
       "  0.9110875725746155,\n",
       "  0.9154673218727112,\n",
       "  0.9185810685157776,\n",
       "  0.9228790998458862,\n",
       "  0.9261660575866699,\n",
       "  0.9289559125900269,\n",
       "  0.9307186603546143,\n",
       "  0.933994472026825],\n",
       " 'val_loss': [5.541996002197266,\n",
       "  4.984335899353027,\n",
       "  4.37005090713501,\n",
       "  4.000641822814941,\n",
       "  3.7339704036712646,\n",
       "  3.5575315952301025,\n",
       "  3.4198038578033447,\n",
       "  3.3158485889434814,\n",
       "  3.22908878326416,\n",
       "  3.155137300491333,\n",
       "  3.114064931869507,\n",
       "  3.065676212310791,\n",
       "  3.0342442989349365,\n",
       "  3.006965398788452,\n",
       "  2.99011492729187,\n",
       "  2.9642412662506104,\n",
       "  2.9650893211364746,\n",
       "  2.9423060417175293,\n",
       "  2.931586265563965,\n",
       "  2.933682918548584,\n",
       "  2.9354939460754395,\n",
       "  2.9115498065948486,\n",
       "  2.9286038875579834,\n",
       "  2.9219071865081787,\n",
       "  2.9238638877868652,\n",
       "  2.916963577270508,\n",
       "  2.925554037094116,\n",
       "  2.9168014526367188,\n",
       "  2.9390738010406494,\n",
       "  2.9332973957061768],\n",
       " 'val_acc': [0.2087084800004959,\n",
       "  0.2640615999698639,\n",
       "  0.312938392162323,\n",
       "  0.34526702761650085,\n",
       "  0.3731047511100769,\n",
       "  0.3893020451068878,\n",
       "  0.40531083941459656,\n",
       "  0.4150846004486084,\n",
       "  0.4246593415737152,\n",
       "  0.4320099353790283,\n",
       "  0.4370647966861725,\n",
       "  0.4408934414386749,\n",
       "  0.4437636733055115,\n",
       "  0.44925788044929504,\n",
       "  0.4518835246562958,\n",
       "  0.45410534739494324,\n",
       "  0.456175297498703,\n",
       "  0.45730772614479065,\n",
       "  0.4601082503795624,\n",
       "  0.4594034254550934,\n",
       "  0.4603700339794159,\n",
       "  0.4652632772922516,\n",
       "  0.46383318305015564,\n",
       "  0.4664960503578186,\n",
       "  0.46604275703430176,\n",
       "  0.46824803948402405,\n",
       "  0.46635502576828003,\n",
       "  0.4697379171848297,\n",
       "  0.46999990940093994,\n",
       "  0.46956953406333923]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = fit(\n",
    "    cfg=cfg,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scaler=scaler,\n",
    "    use_tqdm=cfg.use_tqdm,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc626f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(\n",
    "    obj=history,\n",
    "    path=project_root / \"outputs\" / \"history\" / \"baseline_multihead_history.json\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
