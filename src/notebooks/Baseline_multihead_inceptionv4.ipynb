{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0339322c",
   "metadata": {},
   "source": [
    "## PATH SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636aa887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST be first cell: set multiprocessing method for Windows\n",
    "# import torch.multiprocessing as mp\n",
    "# try:\n",
    "#     mp.set_start_method(\"spawn\", force=True)\n",
    "# except RuntimeError:\n",
    "#     pass  # Already set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d50292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GeoLoc-CVCS'...\n",
      "remote: Enumerating objects: 375, done.\u001b[K\n",
      "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
      "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
      "remote: Total 375 (delta 35), reused 56 (delta 17), pack-reused 284 (from 2)\u001b[K\n",
      "Receiving objects: 100% (375/375), 73.47 MiB | 32.18 MiB/s, done.\n",
      "Resolving deltas: 100% (154/154), done.\n",
      "Updating files: 100% (66/66), done.\n",
      "From https://github.com/MatteoCamillo-code/GeoLoc-CVCS\n",
      " * branch            main       -> FETCH_HEAD\n",
      "Already up to date.\n",
      "CWD: /content/GeoLoc-CVCS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# FOR LOCAL USE THIS LINES\n",
    "# current = Path.cwd()\n",
    "# src_path = current / \"src\" if (current / \"src\").exists() else current.parent\n",
    "\n",
    "# FOR COLAB USE THIS LINE INSTEAD\n",
    "BRANCH_NAME = \"main\"  # Change this to switch branches\n",
    "!git clone -b {BRANCH_NAME} https://github.com/MatteoCamillo-code/GeoLoc-CVCS.git\n",
    "!cd /content/GeoLoc-CVCS && git pull origin {BRANCH_NAME} && cd ..\n",
    "src_path = Path(\"/content/GeoLoc-CVCS/src\").resolve()\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "from utils.paths import find_project_root\n",
    "\n",
    "# Set working directory and sys.path properly\n",
    "project_root = find_project_root(src_path)\n",
    "data_dir = project_root / \"data\"\n",
    "history_dir = project_root / \"outputs\" / \"history\"\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "print(\"CWD:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f450636",
   "metadata": {},
   "source": [
    "## IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c976cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torchvision.models import resnet50, ResNet50_Weights\n",
    "import timm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from configs.baseline_multi_head_ISN import TrainConfig\n",
    "\n",
    "from utils.seed import seed_everything\n",
    "from utils.metrics import overall_val_acc_from_history\n",
    "from utils.io import save_json, read_json\n",
    "from utils.paths import get_next_version, get_current_version\n",
    "from training.runner import fit\n",
    "from training.losses import CrossEntropyWithLabelSmoothing\n",
    "\n",
    "from src.utils.logging import get_logger\n",
    "from src.utils.paths import abs_path\n",
    "\n",
    "from models.multi_head_classifier import MultiHeadClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ad6ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "cfg = TrainConfig()\n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "device = cfg.device if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad64c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/josht000/osv-mini-129k?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.63G/5.63G [00:48<00:00, 125MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/josht000/osv-mini-129k/versions/1/osv5m\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"josht000/osv-mini-129k\")\n",
    "path = path + \"/osv5m\"\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "image_root = path + \"/train_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f05014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val CSV: /content/GeoLoc-CVCS/data/metadata/s2-geo-cells/train_val_split_geocells.csv\n",
      "Cell centers CSV: /content/GeoLoc-CVCS/data/metadata/s2-geo-cells/cell_center_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "train_val_path = data_dir / \"metadata/s2-geo-cells/train_val_split_geocells.csv\"\n",
    "cell_centers_path = data_dir / \"metadata/s2-geo-cells/cell_center_dataset.csv\"\n",
    "\n",
    "train_val_meta = pd.read_csv(train_val_path)\n",
    "cell_centers_df = pd.read_csv(cell_centers_path)\n",
    "\n",
    "# remove duplicates with same cell_id\n",
    "cell_centers_df = cell_centers_df.drop_duplicates(subset='cell_id_token')\n",
    "\n",
    "# Set S2 cell ID as index (assumes first column or 'cell_id' column)\n",
    "if 'cell_id_token' in cell_centers_df.columns:\n",
    "    cell_centers_df = cell_centers_df.set_index('cell_id_token')\n",
    "else:\n",
    "    # Set first column as index if it contains cell IDs\n",
    "    cell_centers_df = cell_centers_df.set_index(cell_centers_df.columns[0])\n",
    "    \n",
    "\n",
    "print(\"Train/val CSV:\", train_val_path)\n",
    "print(\"Cell centers CSV:\", cell_centers_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662ad7d",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4888680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataloader_utils import create_dataloaders\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Create all dataloaders with a single function call\n",
    "loader_dict = create_dataloaders(\n",
    "    image_root=image_root,\n",
    "    csv_path=train_val_path,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.num_workers,\n",
    "    img_size=IMG_SIZE,\n",
    "    seed=cfg.seed,\n",
    "    train_subset_pct=cfg.train_size_pct,\n",
    "    val_subset_pct=cfg.val_size_pct,\n",
    "    scenes=cfg.scenes,\n",
    "    augment=True,\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True if cfg.num_workers > 0 else False,\n",
    "    coarse_label_idx=cfg.coarse_label_idx,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef1e57",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c10203f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output classes urban: [3101, 1850, 1091]\n",
      "Output classes natural: [4561, 2472, 1328]\n"
     ]
    }
   ],
   "source": [
    "# weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "models = {}\n",
    "\n",
    "for sc in cfg.scenes:\n",
    "    inception = timm.create_model('inception_v4', pretrained=True)\n",
    "\n",
    "    # number of classes depends on partition\n",
    "    num_classes = list(map(\n",
    "        lambda idx: len(loader_dict[sc][\"label_maps\"][f\"label_config_{idx + 1}\"]),\n",
    "        cfg.coarse_label_idx\n",
    "    ))\n",
    "\n",
    "    backbone = nn.Sequential(\n",
    "        *list(inception.children())[:-1],\n",
    "        nn.Flatten(1)\n",
    "    )\n",
    "\n",
    "    FEAT_DIM = 1536  # inception_v4 feature dimension\n",
    "\n",
    "    #resnet = resnet.to(device)\n",
    "    # Optional: comment out if it causes issues on Windows/your PyTorch version\n",
    "    # model = torch.compile(model, backend=\"aot_eager\")\n",
    "\n",
    "    model = MultiHeadClassifier(\n",
    "        backbone=backbone,\n",
    "        feat_dim=FEAT_DIM,\n",
    "        head_dims=num_classes,\n",
    "        dropout=cfg.dropout,\n",
    "        coarse_level_idx=cfg.coarse_label_idx,\n",
    "    ).to(device)\n",
    "    \n",
    "    models[sc] = model\n",
    "\n",
    "    print(f\"Output classes {sc}:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "342d07d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized training components for 2 scenes: ['urban', 'natural']\n"
     ]
    }
   ],
   "source": [
    "criterion = CrossEntropyWithLabelSmoothing(ignore_index=-1, smoothing=cfg.label_smoothing)\n",
    "\n",
    "# Create optimizer, scheduler, and scaler for each model\n",
    "optimizers = {}\n",
    "schedulers = {}\n",
    "scalers = {}\n",
    "\n",
    "for scene, model in models.items():\n",
    "    optimizers[scene] = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    schedulers[scene] = StepLR(optimizers[scene], step_size=cfg.scheduler_step_size, gamma=cfg.scheduler_gamma)\n",
    "    scalers[scene] = torch.amp.GradScaler(device=cfg.device, enabled=cfg.amp)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(f\"Initialized training components for {len(models)} scenes: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba589c1",
   "metadata": {},
   "source": [
    "## TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe789ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:09:29] INFO - Starting training baseline_multi_head_ISN for scene urban ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2477230dda5946778eda8e961cc01f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2478b2ec794456287626c93a577c8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:09:50] INFO - Epoch 1/3 | train loss=7.4252 acc=0.47% | val loss=7.2731 acc=0.68% | geo acc={'acc@1km': '0.06%', 'acc@5km': '1.34%', 'acc@25km': '7.95%', 'acc@100km': '15.46%'} | time=21.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6eabb7259474a8d813729e7fefb510b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205bcbd6efd4499eab7cbd61432b25a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:10:11] INFO - Epoch 2/3 | train loss=6.9041 acc=3.59% | val loss=7.1831 acc=1.78% | geo acc={'acc@1km': '0.45%', 'acc@5km': '4.33%', 'acc@25km': '14.82%', 'acc@100km': '20.17%'} | time=20.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a989fcf90e09482ab1261806c17d72ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c4f889e3ce42fdba92eee6c7a15597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:10:31] INFO - Epoch 3/3 | train loss=6.5776 acc=9.56% | val loss=7.1216 acc=2.42% | geo acc={'acc@1km': '1.15%', 'acc@5km': '5.22%', 'acc@25km': '18.13%', 'acc@100km': '23.41%'} | time=19.8s\n",
      "[12:10:32] INFO - Training completed.\n",
      "[12:10:32] INFO - Starting training baseline_multi_head_ISN for scene natural ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3271a7d3477c4a8cbdf0ee6b380392c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb24326a58744d22bab98ec9c16dea6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:11:12] INFO - Epoch 1/3 | train loss=7.5958 acc=2.23% | val loss=7.3010 acc=5.29% | geo acc={'acc@1km': '0.19%', 'acc@5km': '2.28%', 'acc@25km': '7.19%', 'acc@100km': '13.24%'} | time=40.2s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8dfd25cc6e4bf9b633bcf8413c99a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295048ad105f4464acba06fe8bc8edc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:11:50] INFO - Epoch 2/3 | train loss=6.7942 acc=12.37% | val loss=7.0221 acc=9.06% | geo acc={'acc@1km': '0.45%', 'acc@5km': '4.96%', 'acc@25km': '13.91%', 'acc@100km': '22.56%'} | time=37.4s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2de17338024ae68167d5e9ec1282ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5e070647f0485f8cd72157a5de53b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:12:28] INFO - Epoch 3/3 | train loss=6.3150 acc=21.58% | val loss=6.8521 acc=11.62% | geo acc={'acc@1km': '0.56%', 'acc@5km': '6.58%', 'acc@25km': '17.25%', 'acc@100km': '26.73%'} | time=38.0s\n",
      "[12:12:29] INFO - Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Train each scene's model separately\n",
    "histories = {}\n",
    "logger = get_logger(log_file=str(abs_path(cfg.output_dir, \"logs\", \"train.log\")))\n",
    "version = 0\n",
    "\n",
    "for scene in models.keys():\n",
    "    # Get versioned history path\n",
    "    base_name = f\"{cfg.model_name}_{scene}\"\n",
    "    version = get_next_version(history_dir, base_name)\n",
    "    history_path = history_dir / f\"{base_name}_v{version}_history.json\"\n",
    "    \n",
    "    history = fit(\n",
    "        cfg=cfg,\n",
    "        model=models[scene],\n",
    "        data_loader=loader_dict[scene],\n",
    "        cell_centers=cell_centers_df,\n",
    "        optimizer=optimizers[scene],\n",
    "        criterion=criterion,\n",
    "        scaler=scalers[scene],\n",
    "        use_tqdm=cfg.use_tqdm,\n",
    "        scheduler=schedulers[scene],\n",
    "        logger=logger,\n",
    "        scene=scene,\n",
    "        history_path=history_path,\n",
    "        version=version,\n",
    "    )\n",
    "    \n",
    "    histories[scene] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81fe025d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'urban': 0.024173030629754066, 'natural': 0.11624203622341156, 'overall': 0.08913857614977307}\n"
     ]
    }
   ],
   "source": [
    "# version = 3\n",
    "accuracy_list = overall_val_acc_from_history(cfg, project_root, version)\n",
    "print(accuracy_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
