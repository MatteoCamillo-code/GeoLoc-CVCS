{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7598fc20",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73379c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST be first cell: set multiprocessing method for Windows\n",
    "import torch.multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "except RuntimeError:\n",
    "    pass  # Already set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f05181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# FOR LOCAL USE THIS LINES\n",
    "current = Path.cwd()\n",
    "src_path = current / \"src\" if (current / \"src\").exists() else current.parent\n",
    "\n",
    "# FOR COLAB USE THIS LINE INSTEAD\n",
    "# BRANCH_NAME = \"main\"  # Change this to switch branches\n",
    "# !git clone -b {BRANCH_NAME} https://github.com/MatteoCamillo-code/GeoLoc-CVCS.git\n",
    "# !cd /content/GeoLoc-CVCS && git pull origin {BRANCH_NAME} && cd ..\n",
    "# src_path = Path(\"/content/GeoLoc-CVCS/src\").resolve()\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "from utils.paths import find_project_root\n",
    "\n",
    "# Set working directory and sys.path properly\n",
    "project_root = find_project_root(src_path)\n",
    "data_dir = project_root / \"data\"\n",
    "history_dir = project_root / \"outputs\" / \"history\"\n",
    "checkpoint_dir = project_root / \"outputs\" / \"checkpoints\"\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "print(\"CWD:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8996e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from configs.baseline_multi_head import TrainConfig\n",
    "\n",
    "from training.engine import evaluate\n",
    "\n",
    "from utils.seed import seed_everything\n",
    "from utils.paths import get_current_version\n",
    "from utils.checkpointing import load_checkpoint\n",
    "\n",
    "from models.multi_head_classifier import MultiHeadClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c8a513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "cfg = TrainConfig()\n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "device = cfg.device if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d48d3a",
   "metadata": {},
   "source": [
    "## DATA LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18fb49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camil\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
      "Path to dataset files: C:\\Users\\camil\\.cache\\kagglehub\\datasets\\josht000\\osv-mini-129k\\versions\\1/osv5m\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"josht000/osv-mini-129k\")\n",
    "path = path + \"/osv5m\"\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "image_root = path + \"/train_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c406b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\train_val_split_geocells.csv\n",
      "Cell centers CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\cell_center_dataset.csv\n",
      "Cells hierarchy CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\cell_hierarchy_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "train_val_path = data_dir / \"metadata/s2-geo-cells/train_val_split_geocells.csv\"\n",
    "cell_centers_path = data_dir / \"metadata/s2-geo-cells/cell_center_dataset.csv\"\n",
    "cells_hierarchy_path = data_dir / \"metadata/s2-geo-cells/cell_hierarchy_dataset.csv\"\n",
    "\n",
    "train_val_meta = pd.read_csv(train_val_path)\n",
    "cell_centers_df = pd.read_csv(cell_centers_path)\n",
    "cells_hierarchy_df = pd.read_csv(cells_hierarchy_path)\n",
    "\n",
    "# remove duplicates with same cell_id\n",
    "cell_centers_df = cell_centers_df.drop_duplicates(subset='cell_id_token')\n",
    "\n",
    "# Set S2 cell ID as index (assumes first column or 'cell_id' column)\n",
    "if 'cell_id_token' in cell_centers_df.columns:\n",
    "    cell_centers_df = cell_centers_df.set_index('cell_id_token')\n",
    "else:\n",
    "    # Set first column as index if it contains cell IDs\n",
    "    cell_centers_df = cell_centers_df.set_index(cell_centers_df.columns[0])\n",
    "    \n",
    "\n",
    "print(\"Train/val CSV:\", train_val_path)\n",
    "print(\"Cell centers CSV:\", cell_centers_path)\n",
    "print(\"Cells hierarchy CSV:\", cells_hierarchy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46cd31c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataloader_utils import create_dataloaders\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Create all dataloaders with a single function call\n",
    "loader_dict = create_dataloaders(\n",
    "    image_root=image_root,\n",
    "    csv_path=train_val_path,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.num_workers,\n",
    "    img_size=IMG_SIZE,\n",
    "    seed=cfg.seed,\n",
    "    train_subset_pct=cfg.train_size_pct,\n",
    "    val_subset_pct=cfg.val_size_pct,\n",
    "    scenes=cfg.scenes,\n",
    "    augment=True,\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True if cfg.num_workers > 0 else False,\n",
    "    coarse_label_idx=cfg.coarse_label_idx,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a7c5d",
   "metadata": {},
   "source": [
    "##  LOAD MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a8d2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\outputs\\checkpoints\\baseline_multi_head_total_v0.pt\n",
      "Loaded epoch: 28\n"
     ]
    }
   ],
   "source": [
    "# LOAD MODEL FROM CHECKPOINT\n",
    "\n",
    "scene = cfg.scenes[0]\n",
    "base_name = f\"{cfg.model_name}_{scene}\"\n",
    "version = get_current_version(history_dir, base_name)\n",
    "ckpt_path = checkpoint_dir / f\"{base_name}_v{version}.pt\"\n",
    "print(\"Checkpoint:\", ckpt_path)\n",
    "\n",
    "weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "resnet = resnet50(weights=weights)\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1], nn.Flatten(1))\n",
    "FEAT_DIM = 2048\n",
    "num_classes = list(map(\n",
    "    lambda idx: len(loader_dict[scene][\"label_maps\"][f\"label_config_{idx + 1}\"]),\n",
    "    cfg.coarse_label_idx\n",
    "))\n",
    "model = MultiHeadClassifier(\n",
    "    backbone=backbone,\n",
    "    feat_dim=FEAT_DIM,\n",
    "    head_dims=num_classes,\n",
    "    dropout=cfg.dropout,\n",
    "    coarse_level_idx=cfg.coarse_label_idx,\n",
    ").to(device)\n",
    "\n",
    "ckpt = load_checkpoint(str(ckpt_path), model, map_location=device)\n",
    "model.eval()\n",
    "print(\"Loaded epoch:\", ckpt.get(\"epoch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd16f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.losses import CrossEntropyWithLabelSmoothing\n",
    "criterion = CrossEntropyWithLabelSmoothing(ignore_index=-1, smoothing=cfg.label_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0873f325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluations:\n",
      "{'total': {'loss': 7.137075424194336,\n",
      "           'acc': 0.47763484716415405,\n",
      "           'geo_acc': {'acc@1km': '0.64%', 'acc@5km': '6.35%', 'acc@25km': '21.83%', 'acc@100km': '40.12%'}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# start inference code here\n",
    "from pprint import pprint\n",
    "\n",
    "evaluations = {}\n",
    "for scene in cfg.scenes:\n",
    "    evaluation = evaluate(\n",
    "        model,\n",
    "        loader_dict[scene][\"val_loader\"],\n",
    "        cell_centers_df,\n",
    "        cells_hierarchy_df,\n",
    "        loader_dict[scene][\"label_maps\"],\n",
    "        criterion,\n",
    "        cfg.device,\n",
    "        gps_method=cfg.gps_method,\n",
    "        amp=cfg.amp,\n",
    "        use_tqdm=cfg.use_tqdm,\n",
    "    )\n",
    "    evaluations[scene] = evaluation\n",
    "    \n",
    "print(\"Evaluations:\")\n",
    "pprint(evaluations, width=120, sort_dicts=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
