{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636aa887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST be first cell: set multiprocessing method for Windows\n",
    "import torch.multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "except RuntimeError:\n",
    "    pass  # Already set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d50292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# FOR LOCAL USE THIS LINES\n",
    "current = Path.cwd()\n",
    "src_path = current / \"src\" if (current / \"src\").exists() else current.parent\n",
    "\n",
    "# FOR COLAB USE THIS LINE INSTEAD\n",
    "#!git clone https://github.com/MatteoCamillo-code/GeoLoc-CVCS.git\n",
    "#src_path = Path(\"/content/GeoLoc-CVCS/src\").resolve()\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "from utils.paths import find_project_root\n",
    "\n",
    "# Set working directory and sys.path properly\n",
    "project_root = find_project_root(src_path)\n",
    "data_dir = project_root / \"data\"\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "print(\"CWD:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c976cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from dataset.osv_dataset import OSV_mini\n",
    "from configs.baseline import TrainConfig\n",
    "\n",
    "from utils.seed import seed_everything\n",
    "from training.runner import fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ad6ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "cfg = TrainConfig()\n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "device = cfg.device if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad64c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camil\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
      "Path to dataset files: C:\\Users\\camil\\.cache\\kagglehub\\datasets\\josht000\\osv-mini-129k\\versions\\1/osv5m\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"josht000/osv-mini-129k\")\n",
    "path = path + \"/osv5m\"\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "image_root = path + \"/train_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f05014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\train_val_split_geocells.csv\n",
      "Cell centers CSV: F:\\InfTech\\Prodotti\\Python\\GeoLocGit\\GeoLoc-CVCS\\data\\metadata\\s2-geo-cells\\cell_center_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "train_val_path = data_dir / \"metadata/s2-geo-cells/train_val_split_geocells.csv\"\n",
    "cell_centers_path = data_dir / \"metadata/s2-geo-cells/cell_center_dataset.csv\"\n",
    "\n",
    "train_val_meta = pd.read_csv(train_val_path)\n",
    "cell_centers_df = pd.read_csv(cell_centers_path)\n",
    "\n",
    "print(\"Train/val CSV:\", train_val_path)\n",
    "print(\"Cell centers CSV:\", cell_centers_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0), ratio=(3/4, 4/3)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
    "    transforms.RandomApply([transforms.RandomRotation(10)], p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7841039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 100863\n",
      "Val size: 17803\n",
      "Label maps: {'label_config_1': 4741, 'label_config_2': 2508, 'label_config_3': 1336}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = OSV_mini(\n",
    "    image_root=image_root,\n",
    "    csv_path=train_val_path,\n",
    "    transform=train_transform,\n",
    "    split=\"train\",\n",
    "    scene=\"total\",\n",
    "    label_maps=None\n",
    ")\n",
    "\n",
    "val_dataset = OSV_mini(\n",
    "    image_root=image_root,\n",
    "    csv_path=train_val_path,\n",
    "    transform=val_transform,\n",
    "    split=\"val\",\n",
    "    scene=\"total\",\n",
    "    label_maps=train_dataset.label_maps\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Val size:\", len(val_dataset))\n",
    "print(\"Label maps:\", {k: len(v) for k,v in train_dataset.label_maps.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4888680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.osv_dataset import seed_worker, fast_collate\n",
    "\n",
    "BATCH_SIZE = cfg.batch_size\n",
    "NUM_WORKERS = cfg.num_workers\n",
    "PREFETCH_FACTOR = 4\n",
    "\n",
    "# Create a generator for reproducibility with workers\n",
    "g = torch.Generator()\n",
    "g.manual_seed(cfg.seed)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=PREFETCH_FACTOR if NUM_WORKERS > 0 else None,\n",
    "    persistent_workers=True if NUM_WORKERS > 0 else False,\n",
    "    collate_fn=fast_collate,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=PREFETCH_FACTOR if NUM_WORKERS > 0 else None,\n",
    "    persistent_workers=True if NUM_WORKERS > 0 else False,\n",
    "    collate_fn=fast_collate,\n",
    "    worker_init_fn=seed_worker\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c10203f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output classes: 2510\n"
     ]
    }
   ],
   "source": [
    "PARTITION_IDX = 1  # 0,1,2 corresponding to label_config_1/2/3\n",
    "\n",
    "weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "model = resnet50(weights=weights)\n",
    "\n",
    "# number of classes depends on partition\n",
    "num_classes = [\n",
    "    train_val_meta[\"label_config_1\"].nunique(),\n",
    "    train_val_meta[\"label_config_2\"].nunique(),\n",
    "    train_val_meta[\"label_config_3\"].nunique(),\n",
    "]\n",
    "n_out = num_classes[PARTITION_IDX]\n",
    "\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, n_out)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Optional: comment out if it causes issues on Windows/your PyTorch version\n",
    "# model = torch.compile(model, backend=\"aot_eager\")\n",
    "\n",
    "print(\"Output classes:\", n_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28225b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters in the model initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the final fully connected layer (model.fc)\n",
    "# This layer was replaced with a new nn.Linear layer in cell nYgB9PL73PAb\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=cfg.lr,\n",
    "    momentum=cfg.momentum,\n",
    "    weight_decay=cfg.weight_decay,\n",
    "    nesterov=True\n",
    ")\n",
    "scheduler = StepLR(optimizer, step_size=cfg.scheduler_step_size, gamma=cfg.scheduler_gamma)\n",
    "scaler = torch.amp.GradScaler(device=cfg.device, enabled=cfg.amp)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe789ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure your config has:\n",
    "# output_dir=\"outputs\", model_name=\"first_try.pt\"\n",
    "# runner.py uses root_path(cfg.output_dir, \"checkpoints\", cfg.model_name)\n",
    "\n",
    "history = fit(\n",
    "    cfg=cfg,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scaler=scaler,\n",
    "    label_idx=PARTITION_IDX,\n",
    "    use_tqdm=cfg.use_tqdm,\n",
    "    scheduler=None\n",
    ")\n",
    "\n",
    "history\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
